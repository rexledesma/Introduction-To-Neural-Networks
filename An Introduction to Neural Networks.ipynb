{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Neural Networks in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Neural networks are like magical boxes, able to tackle any task you have at hand. Recently, neural networks have been applied to the problems of [real time object recognition for autonomous vehicles](https://eng.uber.com/sbnet/), [visualization of photographs in different artistic styles](https://towardsdatascience.com/artistic-style-transfer-b7566a216431), the creation of [new names for ice cream flavors](http://aiweirdness.com/post/173797162852/ai-scream-for-ice-cream), and even the [generation of fake news](http://www.businessinsider.com/researchers-teach-ai-neural-network-write-fake-reviews-fake-news-2017-8). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![style-transfer](images/style-transfer.png)\n",
    "\n",
    "_Example of cat visualized in the style of a painting, courtesy of [http://kvfrans.com/](http://kvfrans.com/neural-style-explained/)_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear to see that neural networks can be used in a wide variety of domains – the possibilities are endless! Such applications of neural networks have been made possible by previous advances in neural learning, computation hardware, and novel neural network architectures published by academics in the field of deep learning. We will explore neural networks by examining the intuition behind the architecture of the neural network and how the network learns from training examples. After some of the basics have been explained, we’ll make our very own neural network for classifying handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a neural network\n",
    "A [basic neural network](http://neuralnetworksanddeeplearning.com/chap1.html) is commonly visualized as a system of layered nodes. Nodes are connected forward to their successive layer with weights, which scale the values from one node to the next. The scaled values are then added together, and then passed through an activation function to introduce nonlinearity into the system. We do this to allow the network to learn nonlinear relations of the training data. This representation is analogous to the neural connections of a brain – hence the name, neural network. The weights between the nodes of the network correspond to the synapses connecting neurons, and the activation function associated with a node is akin to a threshold needed for the neuron to fire off its action potential to signal other neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![A basic 3-layer neural network](images/basic-nn.png)\n",
    "_A basic 3-layer neural network, courtesy of [http://texexample.net](http://www.texample.net/tikz/examples/neural-network/) ._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Layers\n",
    "In the example above, we see a neural network with three layers. The first layer, the input layer, connects to the intermediate hidden layer, which is connected to the final layer, known as the output layer. The input is fed into the first layer, and then the calculations are applied onto this input to generate the input for the next layer, and this is repeated until we reach the final layer. Since every node in the hidden layer is connected to all activations in the previous layer, we call this type of layer “fully connected” or a dense layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training examples to be fed into this network’s first layer, they must first be represented in vector form. One example is an image, which is inherently represented as pixels with numeric intensities. To pass this image into the neural network, we can condense it (with width $w$ and height $h$) into a vector of column vector of values of size $wh$. Now, the input layer of the neural network can have a $wh$ input nodes to take in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNIST-fc-nn](images/MNIST-fc.png)\n",
    "_Vectorization of a handwritten digit, courtesy of https://ml4a.github.io/ ._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll examine a toy neural network to tackle the problem of classifiying handwritten digits, first pioneered by Yann LeCun (now director of AI at Facebook Research) [in the late 1990s](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf).\n",
    "Here, we have $28\\times28$ sized image representing a handwritten digit. To feed it into our network, we take all the pixels (in this case, $28*28 = 784$) and create an input layer with $784$ nodes. The input layer is fully connected to a hidden layer of $10$ nodes, and then the hidden layer is fully connected to an output layer of $10$ nodes. The output layer of $10$ nodes will generate probabilities for whether the image is the digit $0, 1, \\dots 9$. We assign a label to the image based on the maximum of the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n",
    "\n",
    "#### The Convolution Operator\n",
    "In addition to fully connected layers, we can also have connections in our neural network that function as [convolutions of the the input](http://yann.lecun.com/exdb/publis/pdf/lecun-bengio-95a.pdf). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![convolution](images/conv.png)\n",
    "\n",
    "_A convolution operation, courtesy of [http://cambridgespark.com](http://cambridgespark.com/content/tutorials/convolutional-neural-networks-with-keras/figures/convolve.png)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, we have a matrix $I$ and convolution operator $K$ (also known as a kernel). To achieve convolution, we slide the kernel over the image $I$, and take the weighted sum of the elements of the window in $I$ covered by $K$, using the weight from the corresponding element in $K$. This will generate the output for the convolved image.\n",
    "\n",
    "The kernel, shown in blue, is currently slid over a portion of the image $I$, shown in red. To generate the corresponding output in $I \\ast K$, shown in green, we take the weighted sum: $1*1 + 0*0 + 0*1 + 1*0 + 1*1 + 0*0 + 1*1 + 1*0 + 1*1 = 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we're working with images, we won't need to vectorize them! We can simply apply a convolution operation over the image, and then use the resulting convolution as the input for our next layer. Also, a convolutional layer can have multiple convolutions to generate new feature maps for the next layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of using a convolutional layer is to effectively represent the input of multidimensional images better. Rather than vectorizing the image for a fully connected layer, it is more natural to keep the image in its original representation, and use a convolution instead. This greatly reduces the number of trainable parameters needed for the neural network. Also, this resembles the visual cortex of the brain, where neurons have receptive fields of the visual field - the overlap of all the receptive fields encompasses the visual field, and allows us to process visual information. Similarly, in the convolution operation, the receptive field of a neuron is each sliding of the convolution kernel across the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does a Neural Network Learn?\n",
    "Now, we have an understanding for the basic architecture of a neural network. Essentially, the power of neural networks stems from its ability to gradually learn a task, if given abundant training examples. Through the intricate operations of the network, key features are learned from the training examples so the network can learn to classify new examples that are passed into the network. But how does the network “learn”? \n",
    "\n",
    "Through the work of Rumelhart on [neural learning](https://www.nature.com/articles/323533a0.pdf), he and his collaborators were able to discover the idea of backpropogation (also known as backprop). On a high level, backprop adjusts the weights, or the connections between nodes of the neural network, in such a way that the error of the neural network is decreased at each iteration of backprop. Combined with a technique called [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent), we can iteratively adjust the weights to fine-tune the weights of our neural network. The mathematical derivation of backpropogation applied to a three-layer network, as well as the final adjustment of weights through gradient descent is covered in the appendix.\n",
    "\n",
    "Our neural network can learn by applying backprop and gradient descent optimization on our training dataset multiple times. The number of times we use the training set to train our neural network is denoted as the number of epochs of training.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recent advances of the field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu Activation Function\n",
    "\n",
    "The choice of activation function to use in our neural network is an important topic. We use the activation function to introduce nonlinearity into the system, so our network can learn nonlinear relations of the dataset we are training it on. The choice of activation function is important as it affects how the neural network learns. As shown in the appendix, the derivative of this activation function is taken into account when updating the weights of the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sigmoid and tanh](images/activation-funcs.jpeg)\n",
    "_Graphical representation of sigmoid and tanh activation functions, courtesy of [https://towardsdatascience.com](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with the $sigmoid$ and $tanh$ functions is that their derivatives approaches $0$ once their inputs are out of the range $\\text{[}-2, 2\\text{]}$. This is a problem, since then the amount of change that we apply to our weights through backprop and gradient descent will also go to 0. Essentially, our network will still learn, but very slowly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To alleviate this, [Rectified Linear Units (ReLU)](http://www.cs.toronto.edu/~fritz/absps/reluICML.pdf) were created! ReLu is a nonlinear function that has a derivative of 1 when its input is positive, and 0 if its input is negative. Now, our function has a broader domain, [$0, \\infty$], where it has a nonzero derivative that does not vanish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ReLu](images/ReLu.png)\n",
    "\n",
    "_Graphical representation of ReLU activation function, courtesy of [https://quora.com](https://qph.fs.quoracdn.net/main-qimg-4229dd280e03b7b3a5dc26c808c4b15b)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "When training the network, the goal is to have a network that can generalize - that is, the network works well on both the data you are training it on, as well as data it might encounter in the future. Commonly, networks achieve high accuracy on training data, but not the test data - this is known as overfitting. \n",
    "\n",
    "We can tackle this problem through a method called [dropout](http://jmlr.org/papers/volume15/srivastava14a.old/srivastava14a.pdf). Essentially, during training, we remove some proportion of neurons where the dropout layer is located, and prevent the selected neurons from learning. Intuitively, the remaining neurons in the layer are forced to have more robust weights for the neural network to have high accuracy. This helps hinder the event of overfitting while training the network. Dropout layers are frequently used in conjunction with fully connected layers, rather than convolutional layers are already somewhat resistant to overfitting since they have less trainable parameters compared to fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using a Neural Network Using PyTorch\n",
    "Using what we've learned so far, we'll use a neural network (specifically [LeCun's LeNet-5](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)), to classify handwritten digits. We'll use the [PyTorch](https://pytorch.org/) library to create our neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of LeNet-5\n",
    "The architecture is as follows: ![title](images/LeNet-arch.png)\n",
    "\n",
    "We start start off with $32 \\times 32$ images (we pad the $28 \\times 28$ initial images to achieve this). Here are the layers we will implement:\n",
    "\n",
    "Layers   | Result        \n",
    ":--------|-------------:\n",
    "C1       | (6@28x28)     \n",
    "S2       | (6@14x14)      \n",
    "C3       | (16@10x10)\n",
    "S4       | (16@5x5)\n",
    "C5       | (120@1x1)\n",
    "F6       | (84x1)\n",
    "OUTPUT   | (10x1)\n",
    "\n",
    "$C1, C3, C5$ are convolutional layers with kernel size $5 \\times 5$, as used in the paper. $S2$ and $S4$ are subsampling layers. In LeNet, the subsampling layers actually have trainable weights, but in this implementation, we make a simplifying assumption and use maxpooling instead. The last layer $F6$ is fully connected, with softmax used at the end to get probability scores for each of the 10 classes. We also make another simplifying assumption in layer $C3$ by training the convolution layer on all feature maps available, rather than the feature map split used in the paper.\n",
    "\n",
    "We use the ReLU ($y = \\max(0,x)$) activiation function instead of $tanh$, as ReLU suffers less from the vanishing gradient problem, allowing networks that use ReLU to be more easily trained.\n",
    "\n",
    "Finally, we introduce a dropout layer after the fully connected layers to prevent overfitting of the data, preventing neurons of the same layer from depending on each other during learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=(5,5), padding=2),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=(5, 5)),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 120, kernel_size=(5,5)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, 10),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Softmax(dim=0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the layers of the network in `__init__` for convenience, so we can reference them later. In the `forward` definition, here we define the forward pass of network, to go from input to output. We pass the input `x` successively through each of the layers. Before the output layer, we flatten the dimension of x to be passed into the final layer with the sets of fully connected weights.\n",
    "\n",
    "Finally, since we are looking to see which digit class the input belongs to, we use a softmax output layer to output the posterior probabilities that the input is of some digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeNet = LeNet5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the hyperparameters of the network below. We use 20 epochs of training (i.e. we train our network on 20 passes of our training data, using batches of 100 training samples when updating the weights of the network). \n",
    "\n",
    "The learning rate is small (0.001) as we don't want incredible fluctuations in the weights of our network, as this may cause fluctuations in the error rate in classification as well. Intuitively, this small learning rate will let our network gradually descend to the optimal weights for classification.\n",
    "\n",
    "PyTorch's built-in automatic differentiation so that backpropogation is already taken care for us, if we handle our inputs/outputs as PyTorch `Variable`'s.\n",
    "\n",
    "We'll also use a cross entropy loss function (instead of sum of square errors), as well as the ADAM method of stochastic optimization, rather than plain gradient descent to optimize the weights during training.\n",
    "\n",
    "For convenience, we use PyTorch's built in MNIST dataset to format the data for us for easy enumeration and input into the network for training. We have a dataset set aside for training our network, and we can see the accuracy of our network on new, unused samples in the test dataset. We validate the accuracy on this test dataset to ensure that our network has generalized, by accurately classifying samples it has not seen before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = dsets.MNIST(root='./data/', train=True, transform=trans, download=True)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/', train=False, transform=trans)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Iter [100/600] Loss: 2.2618\n",
      "Epoch [1/20], Iter [200/600] Loss: 2.2435\n",
      "Epoch [1/20], Iter [300/600] Loss: 2.2348\n",
      "Epoch [1/20], Iter [400/600] Loss: 2.2435\n",
      "Epoch [1/20], Iter [500/600] Loss: 2.2350\n",
      "Epoch [1/20], Iter [600/600] Loss: 2.2280\n",
      "Training Accuracy of the model on the 60000 train images: 62%\n",
      "Test Accuracy of the model on the 10000 test images: 67%\n",
      "Epoch [2/20], Iter [100/600] Loss: 2.2282\n",
      "Epoch [2/20], Iter [200/600] Loss: 2.2277\n",
      "Epoch [2/20], Iter [300/600] Loss: 2.2255\n",
      "Epoch [2/20], Iter [400/600] Loss: 2.2276\n",
      "Epoch [2/20], Iter [500/600] Loss: 2.2259\n",
      "Epoch [2/20], Iter [600/600] Loss: 2.2264\n",
      "Training Accuracy of the model on the 60000 train images: 60%\n",
      "Test Accuracy of the model on the 10000 test images: 65%\n",
      "Epoch [3/20], Iter [100/600] Loss: 2.2257\n",
      "Epoch [3/20], Iter [200/600] Loss: 2.2264\n",
      "Epoch [3/20], Iter [300/600] Loss: 2.2283\n",
      "Epoch [3/20], Iter [400/600] Loss: 2.2352\n",
      "Epoch [3/20], Iter [500/600] Loss: 2.2262\n",
      "Epoch [3/20], Iter [600/600] Loss: 2.2263\n",
      "Training Accuracy of the model on the 60000 train images: 63%\n",
      "Test Accuracy of the model on the 10000 test images: 68%\n",
      "Epoch [4/20], Iter [100/600] Loss: 2.2262\n",
      "Epoch [4/20], Iter [200/600] Loss: 2.2307\n",
      "Epoch [4/20], Iter [300/600] Loss: 2.2343\n",
      "Epoch [4/20], Iter [400/600] Loss: 2.2257\n",
      "Epoch [4/20], Iter [500/600] Loss: 2.2264\n",
      "Epoch [4/20], Iter [600/600] Loss: 2.2262\n",
      "Training Accuracy of the model on the 60000 train images: 60%\n",
      "Test Accuracy of the model on the 10000 test images: 65%\n",
      "Epoch [5/20], Iter [100/600] Loss: 2.2256\n",
      "Epoch [5/20], Iter [200/600] Loss: 2.2250\n",
      "Epoch [5/20], Iter [300/600] Loss: 2.2260\n",
      "Epoch [5/20], Iter [400/600] Loss: 2.2251\n",
      "Epoch [5/20], Iter [500/600] Loss: 2.2265\n",
      "Epoch [5/20], Iter [600/600] Loss: 2.2264\n",
      "Training Accuracy of the model on the 60000 train images: 66%\n",
      "Test Accuracy of the model on the 10000 test images: 70%\n",
      "Epoch [6/20], Iter [100/600] Loss: 2.2258\n",
      "Epoch [6/20], Iter [200/600] Loss: 2.2348\n",
      "Epoch [6/20], Iter [300/600] Loss: 2.2254\n",
      "Epoch [6/20], Iter [400/600] Loss: 2.2265\n",
      "Epoch [6/20], Iter [500/600] Loss: 2.2254\n",
      "Epoch [6/20], Iter [600/600] Loss: 2.2257\n",
      "Training Accuracy of the model on the 60000 train images: 71%\n",
      "Test Accuracy of the model on the 10000 test images: 75%\n",
      "Epoch [7/20], Iter [100/600] Loss: 2.2259\n",
      "Epoch [7/20], Iter [200/600] Loss: 2.2247\n",
      "Epoch [7/20], Iter [300/600] Loss: 2.2253\n",
      "Epoch [7/20], Iter [400/600] Loss: 2.2248\n",
      "Epoch [7/20], Iter [500/600] Loss: 2.2261\n",
      "Epoch [7/20], Iter [600/600] Loss: 2.2253\n",
      "Training Accuracy of the model on the 60000 train images: 75%\n",
      "Test Accuracy of the model on the 10000 test images: 79%\n",
      "Epoch [8/20], Iter [100/600] Loss: 2.2268\n",
      "Epoch [8/20], Iter [200/600] Loss: 2.2250\n",
      "Epoch [8/20], Iter [300/600] Loss: 2.2258\n",
      "Epoch [8/20], Iter [400/600] Loss: 2.2347\n",
      "Epoch [8/20], Iter [500/600] Loss: 2.2259\n",
      "Epoch [8/20], Iter [600/600] Loss: 2.2254\n",
      "Training Accuracy of the model on the 60000 train images: 76%\n",
      "Test Accuracy of the model on the 10000 test images: 79%\n",
      "Epoch [9/20], Iter [100/600] Loss: 2.2254\n",
      "Epoch [9/20], Iter [200/600] Loss: 2.2256\n",
      "Epoch [9/20], Iter [300/600] Loss: 2.2254\n",
      "Epoch [9/20], Iter [400/600] Loss: 2.2249\n",
      "Epoch [9/20], Iter [500/600] Loss: 2.2258\n",
      "Epoch [9/20], Iter [600/600] Loss: 2.2248\n",
      "Training Accuracy of the model on the 60000 train images: 77%\n",
      "Test Accuracy of the model on the 10000 test images: 80%\n",
      "Epoch [10/20], Iter [100/600] Loss: 2.2252\n",
      "Epoch [10/20], Iter [200/600] Loss: 2.2251\n",
      "Epoch [10/20], Iter [300/600] Loss: 2.2255\n",
      "Epoch [10/20], Iter [400/600] Loss: 2.2260\n",
      "Epoch [10/20], Iter [500/600] Loss: 2.2249\n",
      "Epoch [10/20], Iter [600/600] Loss: 2.2252\n",
      "Training Accuracy of the model on the 60000 train images: 86%\n",
      "Test Accuracy of the model on the 10000 test images: 88%\n",
      "Epoch [11/20], Iter [100/600] Loss: 2.2249\n",
      "Epoch [11/20], Iter [200/600] Loss: 2.2247\n",
      "Epoch [11/20], Iter [300/600] Loss: 2.2341\n",
      "Epoch [11/20], Iter [400/600] Loss: 2.2251\n",
      "Epoch [11/20], Iter [500/600] Loss: 2.2248\n",
      "Epoch [11/20], Iter [600/600] Loss: 2.2253\n",
      "Training Accuracy of the model on the 60000 train images: 90%\n",
      "Test Accuracy of the model on the 10000 test images: 91%\n",
      "Epoch [12/20], Iter [100/600] Loss: 2.2254\n",
      "Epoch [12/20], Iter [200/600] Loss: 2.2251\n",
      "Epoch [12/20], Iter [300/600] Loss: 2.2249\n",
      "Epoch [12/20], Iter [400/600] Loss: 2.2247\n",
      "Epoch [12/20], Iter [500/600] Loss: 2.2238\n",
      "Epoch [12/20], Iter [600/600] Loss: 2.2344\n",
      "Training Accuracy of the model on the 60000 train images: 91%\n",
      "Test Accuracy of the model on the 10000 test images: 92%\n",
      "Epoch [13/20], Iter [100/600] Loss: 2.2255\n",
      "Epoch [13/20], Iter [200/600] Loss: 2.2250\n",
      "Epoch [13/20], Iter [300/600] Loss: 2.2241\n",
      "Epoch [13/20], Iter [400/600] Loss: 2.2243\n",
      "Epoch [13/20], Iter [500/600] Loss: 2.2284\n",
      "Epoch [13/20], Iter [600/600] Loss: 2.2254\n",
      "Training Accuracy of the model on the 60000 train images: 92%\n",
      "Test Accuracy of the model on the 10000 test images: 93%\n",
      "Epoch [14/20], Iter [100/600] Loss: 2.2244\n",
      "Epoch [14/20], Iter [200/600] Loss: 2.2251\n",
      "Epoch [14/20], Iter [300/600] Loss: 2.2249\n",
      "Epoch [14/20], Iter [400/600] Loss: 2.2237\n",
      "Epoch [14/20], Iter [500/600] Loss: 2.2252\n",
      "Epoch [14/20], Iter [600/600] Loss: 2.2248\n",
      "Training Accuracy of the model on the 60000 train images: 94%\n",
      "Test Accuracy of the model on the 10000 test images: 95%\n",
      "Epoch [15/20], Iter [100/600] Loss: 2.2249\n",
      "Epoch [15/20], Iter [200/600] Loss: 2.2242\n",
      "Epoch [15/20], Iter [300/600] Loss: 2.2254\n",
      "Epoch [15/20], Iter [400/600] Loss: 2.2287\n",
      "Epoch [15/20], Iter [500/600] Loss: 2.2318\n",
      "Epoch [15/20], Iter [600/600] Loss: 2.2248\n",
      "Training Accuracy of the model on the 60000 train images: 94%\n",
      "Test Accuracy of the model on the 10000 test images: 95%\n",
      "Epoch [16/20], Iter [100/600] Loss: 2.2247\n",
      "Epoch [16/20], Iter [200/600] Loss: 2.2238\n",
      "Epoch [16/20], Iter [300/600] Loss: 2.2244\n",
      "Epoch [16/20], Iter [400/600] Loss: 2.2244\n",
      "Epoch [16/20], Iter [500/600] Loss: 2.2253\n",
      "Epoch [16/20], Iter [600/600] Loss: 2.2243\n",
      "Training Accuracy of the model on the 60000 train images: 92%\n",
      "Test Accuracy of the model on the 10000 test images: 93%\n",
      "Epoch [17/20], Iter [100/600] Loss: 2.2256\n",
      "Epoch [17/20], Iter [200/600] Loss: 2.2238\n",
      "Epoch [17/20], Iter [300/600] Loss: 2.2345\n",
      "Epoch [17/20], Iter [400/600] Loss: 2.2250\n",
      "Epoch [17/20], Iter [500/600] Loss: 2.2258\n",
      "Epoch [17/20], Iter [600/600] Loss: 2.2233\n",
      "Training Accuracy of the model on the 60000 train images: 96%\n",
      "Test Accuracy of the model on the 10000 test images: 96%\n",
      "Epoch [18/20], Iter [100/600] Loss: 2.2242\n",
      "Epoch [18/20], Iter [200/600] Loss: 2.2242\n",
      "Epoch [18/20], Iter [300/600] Loss: 2.2237\n",
      "Epoch [18/20], Iter [400/600] Loss: 2.2242\n",
      "Epoch [18/20], Iter [500/600] Loss: 2.2243\n",
      "Epoch [18/20], Iter [600/600] Loss: 2.2237\n",
      "Training Accuracy of the model on the 60000 train images: 95%\n",
      "Test Accuracy of the model on the 10000 test images: 96%\n",
      "Epoch [19/20], Iter [100/600] Loss: 2.2241\n",
      "Epoch [19/20], Iter [200/600] Loss: 2.2244\n",
      "Epoch [19/20], Iter [300/600] Loss: 2.2239\n",
      "Epoch [19/20], Iter [400/600] Loss: 2.2241\n",
      "Epoch [19/20], Iter [500/600] Loss: 2.2246\n",
      "Epoch [19/20], Iter [600/600] Loss: 2.2233\n",
      "Training Accuracy of the model on the 60000 train images: 94%\n",
      "Test Accuracy of the model on the 10000 test images: 95%\n",
      "Epoch [20/20], Iter [100/600] Loss: 2.2243\n",
      "Epoch [20/20], Iter [200/600] Loss: 2.2315\n",
      "Epoch [20/20], Iter [300/600] Loss: 2.2238\n",
      "Epoch [20/20], Iter [400/600] Loss: 2.2324\n",
      "Epoch [20/20], Iter [500/600] Loss: 2.2249\n",
      "Epoch [20/20], Iter [600/600] Loss: 2.2240\n",
      "Training Accuracy of the model on the 60000 train images: 96%\n",
      "Test Accuracy of the model on the 10000 test images: 97%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(LeNet.parameters(), lr=learning_rate)\n",
    "\n",
    "test_acc  = [0]*num_epochs\n",
    "train_acc = [0]*num_epochs\n",
    "for epoch in range(num_epochs):\n",
    "    LeNet.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = LeNet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Iter [{}/{}] Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "    \n",
    "    LeNet.eval()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = Variable(images)\n",
    "        outputs = LeNet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum()\n",
    "    print('Training Accuracy of the model on the 60000 train images: {}%'.format(100 * train_correct / train_total))\n",
    "    \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images)\n",
    "        outputs = LeNet(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {}%'.format(100 * test_correct / test_total))\n",
    "    \n",
    "    train_acc[epoch] = 100 * train_correct / train_total\n",
    "    test_acc[epoch] = 100 * test_correct / test_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we plot the accuracy as we train our neural network, as well as the accuracy of running our network on the dataset set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a03cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = range(1,num_epochs+1)\n",
    "plt.plot(x, train_acc)\n",
    "plt.plot(x, test_acc)\n",
    "plt.title('Train Accuracy and Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('% Accuracy')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieve 97 to 98% accuracy on the test data after 20 epochs. As the network trains, the accuracy increases to this saturation point by the end of training. In the plot below, we show how the network learns over time, with the training accuracy and the test accuracy (of the classification of the training and test datasets, respectively), increase with every iteration of training. Training slows down at around epoch 15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've succesively created a neural network to classify handwritten digits!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Readings\n",
    "\n",
    "1. **Automatic differentiation in PyTorch.** Paszke, A., Gross, S., & Lerer, A. (2017). \n",
    "2. **Dropout: a simple way to prevent neural networks from overfitting.** Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014).\n",
    "3. **Gradient-based Learning Applied to Document Recognition.** LeCun, Y. (1998).\n",
    "4. **ImageNet Classification with Deep Convolutional Neural Networks.** Krizhevsky, A., Sutskever, I., & Hinton, G.E. (2012).\n",
    "5. **Learning representations by backpropagating errors.** Rumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986).\n",
    "6. **Pattern classification.** Richard O. Duda and Peter E. Hart and David G. Stork. (2001).\n",
    "7. **Rectified Linear Units Improve Restricted Boltzmann Machines.** Vinod Nair and Geoffrey E. Hinton. (2010)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivation of Backpropogation (simple 3-layer case)\n",
    "Here, we use a simple cost function, sum of squared errors, and assume that the neural network is 3-layers for simplicity. \n",
    "\n",
    "#### Definitions\n",
    "Define \n",
    "\n",
    "\\begin{align*}\n",
    "x_1, x_2, \\dots x_n  && \\text{inputs to the neural network} \\\\ \n",
    "w_{ji} && \\text{weight from input node $i$ to hidden node $j$} \\\\\n",
    "net_j && \\text{the sum of weighted inputs of input layer to node } j \\\\\n",
    "y_j && \\text{the output of node $j$ after activation function $f_j$} \\\\\n",
    "w_{kj} && \\text{the weight from hidden node $j$ to output node $k$} \\\\\n",
    "net_k && \\text{the sum of weighted activations of hidden layer to node } k \\\\\n",
    "z_k && \\text{the output of node k after activation function f_k} \\\\\n",
    "\\eta && \\text{learning rate for gradient descent}\n",
    "\\end{align*}\n",
    "\n",
    "#### Cost Function\n",
    "We define a cost function $$J(z) = \\frac{1}{2} \\sum\\limits_{k=1}^{n}(t_k - z_k)^2$$ known as the sum of squared errors. $t_k$ is our target value, and $z_k$ is the value generated by the neural network. Intuitively, the cost function outputs a low value if the neural network generates a value close to the target input, and a high value if not.\n",
    "\n",
    "#### Updating weights from hidden to output layer\n",
    "We seek to find $$\\frac{\\partial{J}}{\\partial{w_{kj}}}$$\n",
    "\n",
    "We use the chain rule of calculus and then take the resulting derivatives of the intermediate variables.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial{J}}{\\partial{w_{kj}}} &= \\frac{\\partial{J}}{\\partial{z_k}}\\frac{\\partial{z_k}}{\\partial{net_k}}\\frac{\\partial{net_k}}{\\partial{w_{kj}}} & \\text{by chain rule} \\\\\n",
    "    &= (t_k - z_k)f_k'(net_k)y_j \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Now, we can use this for gradient descent. The new weight, $w_{kj}'$, after gradient descent is:\n",
    "\n",
    "\\begin{align*}\n",
    "w_{kj}' &= w_{kj} - \\eta\\frac{\\partial{J}}{\\partial{w_{kj}}} \\\\ \n",
    "&= w_{kj} - \\eta(t_k - z_k)f_k'(net_k)y_j \\\\ \n",
    "\\end{align*}\n",
    "\n",
    "#### Updating weights from input to hidden layer\n",
    "We seek to find $$\\frac{\\partial{J}}{\\partial{w_{ji}}}$$\n",
    "\n",
    "Again we use the chain rule and then take the resulting derivatives of the intermediate variables.\n",
    "\n",
    "$$\\frac{\\partial{J}}{\\partial{w_{ji}}} = \\frac{\\partial{J}}{\\partial{y_j}}\\frac{\\partial{y_j}}{\\partial{net_j}}\\frac{\\partial{net_j}}{\\partial{w_{ji}}}$$\n",
    "\n",
    "\n",
    "We derive first $\\frac{\\partial{J}}{\\partial{y_j}}$.\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial{J}}{\\partial{y_j}} &= \\frac{\\partial}{\\partial{y_j}} \\frac{1}{2}\\sum\\limits_{k=1}^{n} (t_k - z_k)^{2} & \\text{by definition}\\\\\n",
    "    &=  \\sum\\limits_{k=1}^{n} (t_k - z_k) \\frac{\\partial{z_k}}{\\partial{y_j}} & \\text{by chain rule} \\\\ \n",
    "    &=  \\sum\\limits_{k=1}^{n} (t_k - z_k) \\frac{\\partial{z_k}}{\\partial{net_k}}\\frac{\\partial{net_k}}{\\partial{y_j}} & \\text{by chain rule} \\\\\n",
    "    &=  \\sum\\limits_{k=1}^{n} (t_k - z_k) f_k'(net_k)w_{kj}\n",
    "\\end{align*}\n",
    "\n",
    "Putting it all together, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial{J}}{\\partial{w_{ji}}} &= \\frac{\\partial{J}}{\\partial{y_j}}\\frac{\\partial{y_j}}{\\partial{net_j}}\\frac{\\partial{net_j}}{\\partial{w_{ji}}} \\\\\n",
    "&= \\big{(}\\sum\\limits_{k=1}^{n} (t_k - z_k) f_k'(net_k)w_{kj}\\big{)}f_j'(net_j)x_i\n",
    "\\end{align*}\n",
    "\n",
    "The new weight, $w_{ji}'$, after gradient descent is:\n",
    "\n",
    "\\begin{align*}\n",
    "w_{ji} &= w_{ji} - \\eta\\frac{\\partial{J}}{\\partial{w_{ji}}} \\\\ \n",
    "&= w_{ji} - \\eta\\big{(}\\sum\\limits_{k=1}^{n} (t_k - z_k) f_k'(net_k)w_{kj}\\big{)}f_j'(net_j)x_i \\\\ \n",
    "\\end{align*}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
